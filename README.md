# TFM - AnÃ¡lisis en Tiempo Real de Partidas de Videojuegos Competitivos

Plataforma de anÃ¡lisis en tiempo real de partidas de **League of Legends**, diseÃ±ada como parte del Trabajo de Fin de MÃ¡ster en IngenierÃ­a de Datos.  
La arquitectura combina **procesamiento en streaming**, **almacenamiento NoSQL** y un **dashboard interactivo**, permitiendo consultar estadÃ­sticas actualizadas de las partidas mientras suceden.

---

## ğŸ¯ Objetivo

Desarrollar una plataforma capaz de:
- Ingerir datos en tiempo real desde la API de Riot Games (League of Legends).
- Procesar los eventos con Spark Streaming.
- Detectar eventos tÃ¡cticos relevantes (snowballs, comebacks...).
- Visualizar estadÃ­sticas y anÃ¡lisis contextual en un dashboard interactivo.
- Integrar lÃ³gica basada en reglas y modelos ligeros de ML.

---

## ğŸ§± Arquitectura

![Arquitectura del proyecto](./docs/arquitectura_lol_analytics.png)

**Componentes principales:**
- **Zookeeper**: CoordinaciÃ³n de los brokers Kafka.
- **Kafka Cluster (3 brokers)**: Ingesta y distribuciÃ³n de eventos en tiempo real.
- **MongoDB**: Almacenamiento NoSQL para datos procesados.
- **API**: Servicio REST para exponer datos a terceros.
- **Riot Fetcher**: ObtenciÃ³n de datos desde la API oficial de Riot Games.
- **Ingestion**: Procesamiento y transformaciÃ³n de datos.
- **Dashboard**: Interfaz grÃ¡fica con mÃ©tricas y visualizaciones en Streamlit.

---

## ğŸš€ TecnologÃ­as utilizadas

| TecnologÃ­a     | Uso                                |
|----------------|-----------------------------------|
| **Docker**     | ContenedorizaciÃ³n y orquestaciÃ³n  |
| **Kafka**      | Streaming de datos                |
| **Zookeeper**  | CoordinaciÃ³n de Kafka             |
| **MongoDB**    | Base de datos NoSQL               |
| **Python**     | Servicios backend y procesadores  |
| **Streamlit**  | Dashboard interactivo             |
| **FastAPI**    | ExposiciÃ³n de datos vÃ­a API REST  

--- 

## ğŸ“ Estructura
```plaintext
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ api/ # Servicio FastAPI
â”‚ â”œâ”€â”€ dashboard/ # Dashboard en Streamlit
â”‚ â”œâ”€â”€ ingestion/ # Procesamiento de datos
â”‚ â””â”€â”€ riot_fetcher/ # ConexiÃ³n con la API de Riot Games
â”œâ”€â”€ data/ # Datos persistentes (MongoDB, Kafka)
â”œâ”€â”€ connect
â”œâ”€â”€ output
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ api/ 
â”‚ â”œâ”€â”€ dashboard/ 
â”‚ â”œâ”€â”€ ingestion/ 
â”‚ â””â”€â”€ riot_fetcher/
â”œâ”€â”€ .env 
â”œâ”€â”€ docs/ # Diagramas y documentaciÃ³n
â”œâ”€â”€ init-topics.sh # Script para inicializar tÃ³picos Kafka
â”œâ”€â”€ docker-compose.yml # OrquestaciÃ³n de contenedores
â”œâ”€â”€ Makefile # Comandos simplificados para levantar el entorno
â””â”€â”€ README.md # Este archivo
```
---

## ğŸ›  Requisitos

```bash
pip install -r requirements.txt

### ğŸ” ConfiguraciÃ³n de clave API

Este proyecto requiere una clave vÃ¡lida de Riot Games.  
Por seguridad, esta clave no estÃ¡ incluida en el repositorio.

Antes de ejecutar los scripts, crea un archivo:

```plaintext
shared/onfig.py
```

con el siguiente contenido:

```python
RIOT_API_KEY = "tu_clave_aquÃ­"
```

Este archivo estÃ¡ ignorado en `.gitignore` y debe crearse manualmente en cada entorno.
ğŸ’¡ Puedes usar como plantilla el archivo de ejemplo:

```plaintext
shared/config_example.py
```

## âš¡ Comandos RÃ¡pidos

Antes de empezar, asegÃºrate de tener Docker y Make instalados.  
En Windows puedes instalar `make` con:
```bash
winget install GnuWin32.Make
```

Levantar todos los servicios
```bash
make up
```

Ver logs
```bash
make logs
```

Apagar servicios
```bash
make down
```

Reiniciar todo y reconstruir imÃ¡genes
```bash
make reset
```

Verificar contenedores en ejectuciÃ³n
```bash
make ps
```

Re-crear tÃ³picos Kafka
```bash
make recreate-topics
```

---

## ğŸš€ CÃ³mo ejecutar el proyecto

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/laurasc14/TFM-LoL-RealTime-Analytics.git
   cd TFM-LoL-RealTime-Analytics
   ```
2. **Levantar la infraestructura**
    ```bash
   make up
   ```
3. (Opcional) Incializar tÃ³picos Kafka
    ```bash
   make init-topics
   ```
4. Detener entorno
    ```bash
   make down
   ```

---

## ğŸ”§ Comandos Ãºtiles
**Crear un nuevo tÃ³pico:**
   ```bash
   docker exec -it kafka1 kafka-topics.sh --create --topic <nombre> --partitions 3 --replication-factor 3 --bootstrap-server kafka1:9092
   ```
**Probar productor/consumidor:**
   ```bash
   docker exec -it kafka1 kafka-console-producer.sh --broker-list kafka1:9092 --topic test
   docker exec -it kafka1 kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic test --from-beginning
   ```

---

## ğŸ“Š TÃ³picos Kafka

| TÃ³pico        | Particiones | ReplicaciÃ³n | RetenciÃ³n |
| ------------- | ----------- | ----------- | --------- |
| `lol-matches` | 6           | 3           | 7 dÃ­as    |
| `lol-players` | 6           | 3           | 7 dÃ­as    |
| `lol-events`  | 6           | 3           | 3 dÃ­as    |

---

## ğŸ”® PrÃ³ximos pasos

- Implementar autenticaciÃ³n y seguridad en la API.
- Agregar almacenamiento histÃ³rico optimizado.
- Mejorar las visualizaciones del dashboard.
- Desplegar en entorno cloud para pruebas externas.

---

## Autor
Proyecto desarrollado por Laura SolÃ© como parte del Trabajo Fin de MÃ¡ster, UCM.
